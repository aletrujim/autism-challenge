{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de evaluacion\n",
    "\n",
    "El framework se evalúa con un enfoque de validación cruzada. Las métricas utilizadas son las AUC bajo el ROC y la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from problem import get_cv\n",
    "\n",
    "def evaluation(X, y):\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = get_cv(X, y)\n",
    "    results = cross_validate(pipe, X, y, scoring=['roc_auc', 'accuracy'], cv=cv,\n",
    "                             verbose=1, return_train_score=True,\n",
    "                             n_jobs=1)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "data_train, labels_train = get_train_data()\n",
    "\n",
    "#data_train_anatomy = data_train[[col for col in data_train.columns if col.startswith('anatomy')]]\n",
    "#data_train_functional = data_train[[col for col in data_train.columns if col.startswith('fmri')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureExtractor\n",
    "\n",
    "FeatureExtractor extrae información de conectividad estructural y funcional y los *concatena*. \n",
    "Tener en cuenta que cada columna contendrá en su nombre ya sea connectome o anatomía dependiendo del tipo de característica. Se usará para entrenar diferentes clasificadores más adelante.\n",
    "\n",
    "Connectome funcional: Una matriz de correlación, también se puede ver como un \"gráfico\": un conjunto de nodos, conectados por bordes. Cuando estos nodos son regiones del cerebro y los bordes capturan las interacciones entre ellos, este gráfico es un \"conectoma funcional\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn import preprocessing\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "def _load_fmri(fmri_filenames):\n",
    "    \"\"\"cargar series de tiempo extraídas de la fMRI usando un atlas específico\"\"\"\n",
    "    return np.array([pd.read_csv(subject_filename,\n",
    "                                 header=None).values\n",
    "                     for subject_filename in fmri_filenames])\n",
    "\n",
    "# BaseEstimator: Clase base para todos los estimadores en scikit-learn\n",
    "# TransformerMixin: Clase Mixin para todos los transformadores en scikit-learn\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # transformador que cargará las series de tiempo de un fmri y calcula matrix connectome\n",
    "        # ConnectivityMeasure: conectividad funcional entre regiones de interés\n",
    "        self.transformer_fmri = make_pipeline(\n",
    "            FunctionTransformer(func=_load_fmri, validate=False),\n",
    "            ConnectivityMeasure(kind='correlation', vectorize=True))\n",
    "\n",
    "        \n",
    "    def fit(self, X_df, y):       \n",
    "        # especifico que fmri usar \n",
    "        fmri_filenames = X_df['fmri_msdl'] \n",
    "        self.transformer_fmri.fit(fmri_filenames, y) \n",
    "        fmri_filenames2 = X_df['fmri_power_2011'] \n",
    "        self.transformer_fmri.fit(fmri_filenames2, y)\n",
    "        '''\n",
    "        fmri = ['fmri_basc064', 'fmri_basc122', 'fmri_basc197', 'fmri_craddock_scorr_mean',\n",
    "        'fmri_harvard_oxford_cort_prob_2mm', 'fmri_motions', 'fmri_msdl (atlas)', 'fmri_power_2011 (atlas)',\n",
    "        'fmri_select']\n",
    "        '''\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        # obtengo fmri especifico. sujeto - atlas(./data/fmri/msdl/1932355398536124106/run_1/193...)\n",
    "        fmri_filenames = X_df['fmri_msdl']  \n",
    "        # data = connectome: es un conjunto de conexiones que representa las interacciones cerebrales entre regiones\n",
    "        X_connectome = self.transformer_fmri.transform(fmri_filenames)\n",
    "        X_connectome = pd.DataFrame(X_connectome, index=X_df.index)\n",
    "        X_connectome.columns = ['connectome_{}'.format(i)\n",
    "                                for i in range(X_connectome.columns.size)]     \n",
    "        fmri_filenames2 = X_df['fmri_power_2011']\n",
    "        X_connectome2 = self.transformer_fmri.transform(fmri_filenames2)\n",
    "        X_connectome2 = pd.DataFrame(X_connectome2, index=X_df.index)\n",
    "        X_connectome2.columns = ['connectome2_{}'.format(i)\n",
    "                                for i in range(X_connectome2.columns.size)]   \n",
    "                \n",
    "        # obtiene la información anatómica\n",
    "        X_anatomy = X_df[[col for col in X_df.columns\n",
    "                          if col.startswith('anatomy')]]       \n",
    "        \n",
    "        X_participants = X_df[[col for col in X_df.columns\n",
    "                          if col.startswith('participants')]]\n",
    "                       \n",
    "        # concatenar la data\n",
    "        concat = pd.concat([X_connectome, X_connectome2, X_anatomy, X_participants], axis=1)\n",
    "    \n",
    "        concat[(concat['anatomy_select'] == 1)]    \n",
    "        concat['participants_sex'] = concat['participants_sex'].map({'F': 1, 'M': 0})\n",
    "\n",
    "        return concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "\n",
    "Formando 2 clasificadores independientes en las funciones derivadas de sMRI y fMRI. Luego, se usará un meta clasificador para combinar ambas informaciones. Dejamos afuera algunos datos para poder entrenar el meta clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Classifiers\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "#from sklearn.dummy import DummyRegressor\n",
    "#from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#preprocessing\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.preprocessing import minmax_scale\n",
    "#from sklearn.preprocessing import MaxAbsScaler\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "#from sklearn.preprocessing.data import QuantileTransformer\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):  \n",
    "        \n",
    "        # StandardScaler: Estandariza las características eliminando la media y escalando a la varianza de la unidad    \n",
    "        # Prueba de clasificadores:\n",
    "        # MLPClassifier : Clasificador de perceptrón multicapa. Optimiza la función de pérdida de registros usando \n",
    "        #  LBFGS (Broyden–Fletcher–Goldfarb–Shanno algorithm): método iterativo para resolver probl no lineales de optimización no lineal \n",
    "        #  o SGD (descenso de gradiente estocástico): aprendizaje discriminatorio de clasificadores lineales bajo func de pérdida convexa\n",
    "                \n",
    "        self.clf_connectome = make_pipeline(StandardScaler(),\n",
    "                                            MLPClassifier(alpha=1))\n",
    "        self.clf_connectome2 = make_pipeline(StandardScaler(),\n",
    "                                            MLPClassifier(alpha=1))\n",
    "        self.clf_anatomy = make_pipeline(StandardScaler(),\n",
    "                                         MLPClassifier(alpha=1))       \n",
    "        self.clf_participants = make_pipeline(StandardScaler(),\n",
    "                                         MLPClassifier(alpha=1))\n",
    "        self.meta_clf = MLPClassifier(alpha=1)\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        # obtener data\n",
    "        X_anatomy = X[[col for col in X.columns \n",
    "                       if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "        X_connectome2 = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome2')]]\n",
    "        X_participants = X[[col for col in X.columns\n",
    "                            if col.startswith('participants')]]\n",
    "        \n",
    "        # entrenamiento y validacion \n",
    "        train_idx, validation_idx = train_test_split(range(y.size),\n",
    "                                                     test_size=0.33, \n",
    "                                                     shuffle=True,\n",
    "                                                     random_state=None) \n",
    "        \n",
    "        # pandas.DataFrame.iloc: Indización basada en la ubicación de enteros \n",
    "        # para la selección por posición.\n",
    "        X_anatomy_train = X_anatomy.iloc[train_idx]\n",
    "        X_anatomy_validation = X_anatomy.iloc[validation_idx]\n",
    "        X_connectome_train = X_connectome.iloc[train_idx]\n",
    "        X_connectome_validation = X_connectome.iloc[validation_idx]\n",
    "        X_connectome2_train = X_connectome2.iloc[train_idx]\n",
    "        X_connectome2_validation = X_connectome2.iloc[validation_idx]\n",
    "        X_participants_train = X_participants.iloc[train_idx]\n",
    "        X_participants_validation = X_participants.iloc[validation_idx]\n",
    "        \n",
    "        y_train = y[train_idx]\n",
    "        y_validation = y[validation_idx]\n",
    "\n",
    "        self.clf_connectome.fit(X_connectome_train, y_train)\n",
    "        self.clf_connectome2.fit(X_connectome2_train, y_train)\n",
    "        self.clf_anatomy.fit(X_anatomy_train, y_train)\n",
    "        self.clf_participants.fit(X_participants_train, y_train)\n",
    "\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(\n",
    "            X_connectome_validation)\n",
    "        y_connectome2_pred = self.clf_connectome2.predict_proba(\n",
    "            X_connectome2_validation)\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(\n",
    "            X_anatomy_validation)\n",
    "        y_participants_pred = self.clf_participants.predict_proba(\n",
    "            X_participants_validation)\n",
    "\n",
    "        self.meta_clf.fit(\n",
    "            np.concatenate([y_connectome_pred, y_connectome2_pred,  \n",
    "                            y_anatomy_pred, y_participants_pred], axis=1),\n",
    "            y_validation)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # Predecir usando el clasificador\n",
    "    # Realizar la clasificación en una matriz de vectores de prueba X.\n",
    "    def predict(self, X):\n",
    "        X_anatomy = X[[col for col in X.columns \n",
    "                       if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "        X_connectome2 = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome2')]]\n",
    "\n",
    "        X_participants = X[[col for col in X.columns\n",
    "                            if col.startswith('participants')]]        \n",
    "\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(X_anatomy)\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(X_connectome)\n",
    "        y_connectome2_pred = self.clf_connectome2.predict_proba(X_connectome2)\n",
    "        y_participants_pred = self.clf_participants.predict_proba(X_participants)\n",
    "\n",
    "        return self.meta_clf.predict(\n",
    "            np.concatenate([y_connectome_pred, y_connectome2_pred,  \n",
    "                            y_anatomy_pred, y_participants_pred], axis=1))\n",
    "\n",
    "    # metodo: Estimaciones de probabilidad de retorno para el vector de prueba X.\n",
    "    def predict_proba(self, X):\n",
    "        X_anatomy = X[[col for col in X.columns \n",
    "                       if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "        X_connectome2 = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome2')]]\n",
    "        X_participants = X[[col for col in X.columns\n",
    "                            if col.startswith('participants')]]\n",
    "\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(X_anatomy)\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(X_connectome)\n",
    "        y_connectome2_pred = self.clf_connectome2.predict_proba(X_connectome2)\n",
    "        y_participants_pred = self.clf_participants.predict_proba(X_participants)\n",
    "\n",
    "        return self.meta_clf.predict_proba(\n",
    "            np.concatenate([y_connectome_pred, y_connectome2_pred,  \n",
    "                            y_anatomy_pred, y_participants_pred], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(np.mean(results['train_roc_auc']),\n",
    "                                                        np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(np.mean(results['test_roc_auc']),\n",
    "                                                          np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test_05:\n",
    "\n",
    "Training score ROC-AUC: 0.935 +- 0.010\n",
    "Validation score ROC-AUC: 0.704 +- 0.037 \n",
    "\n",
    "Training score accuracy: 0.871 +- 0.016\n",
    "Validation score accuracy: 0.652 +- 0.030\n",
    "\n",
    "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 18.9min finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
